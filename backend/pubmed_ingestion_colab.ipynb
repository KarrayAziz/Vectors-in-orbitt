{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß¨ PubMed to Qdrant Cloud Ingestion Notebook\n",
                "\n",
                "This notebook allows you to fetch biomedical articles from PubMed, generate embeddings using Colab's GPU, and upsert them into **Qdrant Cloud**.\n",
                "\n",
                "### üöÄ Setup Instructions:\n",
                "1. Go to **Edit -> Notebook settings** and ensure **GPU** is selected.\n",
                "2. Replace the `URL` and `API_KEY` in the configuration cell with your Qdrant Cloud credentials.\n",
                "3. Run all cells."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q qdrant-client sentence-transformers biopython"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚öôÔ∏è Configuration\n",
                "Replace these placeholders with your Qdrant Cloud Cluster details."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from qdrant_client import QdrantClient\n",
                "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
                "from Bio import Entrez\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import torch\n",
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "# --- QDRANT CLOUD CONFIG ---\n",
                "QDRANT_URL = \"YOUR_QDRANT_CLOUD_URL\"  # e.g., https://xxxxxx.aws.cloud.qdrant.io:6333\n",
                "QDRANT_API_KEY = \"YOUR_API_KEY\"\n",
                "COLLECTION_NAME = \"Articles\"\n",
                "VECTOR_SIZE = 384\n",
                "VECTOR_NAME = \"text\"\n",
                "\n",
                "# --- PUBMED CONFIG ---\n",
                "Entrez.email = \"your_email@example.com\"\n",
                "\n",
                "# Initialize Client\n",
                "client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üõ†Ô∏è Define Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def init_collection():\n",
                "    if not client.collection_exists(COLLECTION_NAME):\n",
                "        print(f\"Creating collection: {COLLECTION_NAME}\")\n",
                "        client.create_collection(\n",
                "            collection_name=COLLECTION_NAME,\n",
                "            vectors_config={\n",
                "                VECTOR_NAME: VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE)\n",
                "            }\n",
                "        )\n",
                "    else:\n",
                "        print(f\"Collection {COLLECTION_NAME} already exists.\")\n",
                "\n",
                "def fetch_pubmed_articles(from_date=None, max_results=500):\n",
                "    query = \"hasabstract[text]\"\n",
                "    if from_date:\n",
                "        query += f\" AND ({from_date}[PDAT] : 3000[PDAT])\"\n",
                "\n",
                "    print(f\"Searching PubMed for: {query}\")\n",
                "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results, sort=\"pub+date\")\n",
                "    search_results = Entrez.read(handle)\n",
                "    pmids = search_results[\"IdList\"]\n",
                "\n",
                "    if not pmids:\n",
                "        return []\n",
                "\n",
                "    print(f\"Fetching {len(pmids)} articles...\")\n",
                "    fetch_handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(pmids), rettype=\"abstract\", retmode=\"xml\")\n",
                "    records = Entrez.read(fetch_handle)\n",
                "    \n",
                "    articles = []\n",
                "    for article in records[\"PubmedArticle\"]:\n",
                "        medline = article[\"MedlineCitation\"]\n",
                "        pmid = str(medline[\"PMID\"])\n",
                "        art = medline[\"Article\"]\n",
                "        \n",
                "        abstract = \" \".join(art[\"Abstract\"][\"AbstractText\"]) if \"Abstract\" in art else \"\"\n",
                "        \n",
                "        articles.append({\n",
                "            \"pmid\": pmid,\n",
                "            \"title\": art.get(\"ArticleTitle\", \"\"),\n",
                "            \"abstract\": abstract,\n",
                "            \"url\": f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\"\n",
                "        })\n",
                "    return articles\n",
                "\n",
                "def run_ingestion(from_date=None, max_results=1000):\n",
                "    # 1. Init\n",
                "    init_collection()\n",
                "    \n",
                "    # 2. Fetch\n",
                "    articles = fetch_pubmed_articles(from_date=from_date, max_results=max_results)\n",
                "    if not articles:\n",
                "        print(\"No articles found.\")\n",
                "        return\n",
                "    \n",
                "    # 3. Embed (GPU)\n",
                "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "    print(f\"Generating embeddings on: {device.upper()}\")\n",
                "    model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
                "    \n",
                "    abstracts = [a[\"abstract\"] for a in articles]\n",
                "    vectors = model.encode(abstracts, show_progress_bar=True)\n",
                "    \n",
                "    # 4. Upsert\n",
                "    print(f\"Upserting {len(articles)} points to Qdrant Cloud...\")\n",
                "    points = []\n",
                "    for i, (art, emb) in enumerate(zip(articles, vectors)):\n",
                "        points.append(PointStruct(\n",
                "            id=int(art[\"pmid\"]),\n",
                "            vector={VECTOR_NAME: emb.tolist()},\n",
                "            payload=art\n",
                "        ))\n",
                "    \n",
                "    client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
                "    print(\"‚úÖ Ingestion Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ Run Ingestion"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set your date here or leave as None for initial load\n",
                "DATE_TO_FETCH = \"2026/01/29\"\n",
                "\n",
                "run_ingestion(from_date=DATE_TO_FETCH, max_results=1000)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}